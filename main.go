// Code generated by hertz generator.

package main

import (
	"cex-hertz/biz/dal"
	"cex-hertz/biz/handler"
	"cex-hertz/biz/service"
	"cex-hertz/biz/util"
	"cex-hertz/conf"
	rootHandler "cex-hertz/handler"
	"cex-hertz/middleware"
	cexserver "cex-hertz/server"
	"context"
	"github.com/cloudwego/hertz/pkg/app/middlewares/server/recovery"
	"github.com/cloudwego/hertz/pkg/app/server"
	"github.com/cloudwego/hertz/pkg/common/hlog"
	"github.com/hertz-contrib/cors"
	"github.com/hertz-contrib/gzip"
	"github.com/hertz-contrib/logger/accesslog"
	"github.com/hertz-contrib/pprof"
	"go.uber.org/zap/zapcore"
	"gopkg.in/natefinch/lumberjack.v2"
	"os"
	"os/signal"
	"strconv"
	"syscall"
	"time"
)

func main() {
	cfg := conf.GetConf()
	dal.Init()
	// GORM DB 初始化和自动迁移已由 dal.Init() 内部完成，无需重复初始化

	h := server.New(
		server.WithExitWaitTime(10 * time.Second),
	)
	// 注册优雅关闭钩子，保证Kafka消费者收尾
	h.OnShutdown = append(h.OnShutdown, func(ctx context.Context) {
		service.StopOrderKafkaConsumerWithTimeout(10 * time.Second)
	})

	hsPort := cfg.Hertz.WsPort
	if len(hsPort) > 0 && hsPort[0] == ':' {
		hsPort = hsPort[1:]
	}
	wsServer := cexserver.NewWebSocketServer(":" + hsPort)
	defer h.Shutdown(context.Background())
	defer wsServer.Shutdown(context.Background())

	// 初始化 Postgres 连接池（如有需要可调用对应初始化）
	// 初始化 Kafka Writer
	service.InitKafkaWriter(cfg.Kafka.Brokers, cfg.Kafka.Topics["trade"])
	// 初始化订单Kafka Writer和消费者（批量入库）
	service.InitOrderKafkaWriter(cfg.Kafka.Topics["order"])
	// 替换为本地RocksDB补偿恢复
	service.RecoverCompensateOrders()
	service.StartOrderKafkaConsumer(cfg.Kafka.Topics["order"])

	// 初始化 Consul 并注册撮合引擎节点
	consulAddrs := cfg.Registry.RegistryAddress // []string
	if len(consulAddrs) == 0 {
		panic("Consul address list is empty")
	}
	matchPort := cfg.MatchEngine.MatchPort
	// 使用多地址高可用
	consulHelper, err := service.NewConsulHelperWithAddrs(consulAddrs)
	if err != nil {
		panic(err)
	}

	// 初始化 PartitionManager，支持多个 Consul 地址
	pm, err := service.NewPartitionManager(consulAddrs)
	if err != nil {
		hlog.Fatalf("初始化 PartitionManager 失败: %v", err)
	}
	if err := pm.LoadFromConsul(); err != nil {
		hlog.Fatalf("加载分区表失败: %v", err)
	}
	localIP := util.GetLocalIP()
	localAddr := localIP + ":" + strconv.Itoa(matchPort)
	partitionTable := pm.GetPartitionTable()
	// 动态获取本地 worker 负责的 symbol 列表
	symbolSet := make(map[string]struct{})
	for _, p := range partitionTable.Partitions {
		for _, w := range p.Workers {
			if w == localAddr {
				for _, s := range p.Symbols {
					symbolSet[s] = struct{}{}
				}
			}
		}
	}
	symbols := make([]string, 0, len(symbolSet))
	for s := range symbolSet {
		symbols = append(symbols, s)
	}
	// worker注册到Consul，直接用 localAddr 作为唯一ID
	if err := consulHelper.RegisterMatchEngine(localAddr, symbols, matchPort); err != nil {
		hlog.Fatalf("worker注册到Consul失败: %v", err)
	}

	// 本地 worker 地址（可从配置）
	//localIP := util.GetLocalIP()
	//localAddr := localIP + ":" + strconv.Itoa(matchPort)
	// 初始化撮合引擎，支持动态分区扩展
	broadcaster := func(symbol string, msg []byte) {
		cexserver.Broadcast(symbol, msg)
	}
	unicast := func(userID string, msg []byte) {
		cexserver.Unicast(userID, msg)
	}
	matchEngine := service.NewPartitionAwareMatchEngine(pm, localAddr, broadcaster, unicast)
	// 可将 matchEngine 注入到 handler 或 service 层，供下单、撮合等业务调用

	// 注入全局 handler 层撮合引擎实例，避免循环依赖
	rootHandler.SetEngine(matchEngine)
	cexserver.InjectEngine(matchEngine)

	// 注入撮合结果 websocket 推送方法，避免循环依赖
	service.MatchResultPusher = cexserver.PushMatchResult

	// 启动基于 Consul 分布式锁的 K 线补偿定时任务
	if consulHelper.Client() != nil {
		service.StartKlineCompensateTask(consulHelper.Client())
	}

	// 启动自动扩缩容调度器（每分钟检查一次）
	metrics := &service.MockPartitionMetrics{} // TODO: 替换为真实采集实现
	autoScaler := service.NewPartitionAutoScaler(pm, metrics, time.Minute)
	go autoScaler.Run(context.Background())

	registerMiddleware(h)
	registerRoutes(h)

	go func() {
		h.Spin()
	}()
	go func() {
		wsServer.Spin()
	}()

	quit := make(chan os.Signal, 1)
	signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
	<-quit

	// 优雅关闭Kafka订单写入协程
	service.ShutdownOrderKafkaWriter()
}

func registerMiddleware(h *server.Hertz) {

	hlog.SetLevel(conf.LogLevel())
	hlog.SetOutput(zapcore.AddSync(&lumberjack.Logger{
		Filename:   conf.GetConf().Hertz.LogFileName,
		MaxSize:    conf.GetConf().Hertz.LogMaxSize,
		MaxBackups: conf.GetConf().Hertz.LogMaxBackups,
		MaxAge:     conf.GetConf().Hertz.LogMaxAge,
	}))
	// pprof
	if conf.GetConf().Hertz.EnablePprof {
		pprof.Register(h)
	}

	// gzip
	if conf.GetConf().Hertz.EnableGzip {
		h.Use(gzip.Gzip(gzip.DefaultCompression))
	}

	// access log
	if conf.GetConf().Hertz.EnableAccessLog {
		h.Use(accesslog.New())
	}

	// recovery
	h.Use(recovery.Recovery())

	// cores
	h.Use(cors.Default())
	middleware.Register(h)
}

func registerRoutes(h *server.Hertz) {
	h.GET("/ping", handler.Ping)
	orderGroup := h.Group("/api")
	//orderGroup.Use(middleware.DistributedRouteMiddleware())
	orderGroup.POST("/order", handler.SubmitOrder)
	orderGroup.GET("/order/:id", handler.GetOrder)
	orderGroup.GET("/orders", handler.ListOrders)
	orderGroup.POST("/order/cancel", handler.CancelOrder)
	orderGroup.GET("/balance", handler.GetBalance)
	orderGroup.GET("/positions", handler.GetPositions)
	orderGroup.GET("/depth", handler.GetDepth)
	orderGroup.GET("/trades", handler.GetTrades)
	orderGroup.GET("/ticker", handler.GetTicker)
	orderGroup.GET("/kline", handler.GetKline)
}
